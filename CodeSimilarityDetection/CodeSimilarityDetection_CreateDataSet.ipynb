{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12beff2b",
   "metadata": {},
   "source": [
    "# 0. 필요 라이브러리 및 변수, 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6160b87",
   "metadata": {},
   "source": [
    "## import library & package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41b3b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from collections import deque\n",
    "from transformers import AutoTokenizer\n",
    "# from transformers import AutoModel, AutoModelForSequenceClassification\n",
    "# from datasets import load_dataset, load_metric\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4672ad-5115-467e-8b74-48705cb6a4dd",
   "metadata": {},
   "source": [
    "**BM25: 키워드 기반 랭킹 알고리즘**\n",
    "- 주어진 쿼리에 대해 문서와의 연관성을 평가하는 랭킹 함수\n",
    "- Bag-of-words 개념을 사용하여 쿼리에 있는 용어가 각각의 문서에 얼마나 자주 등장하는지를 평가\n",
    "    - 이때 IDF값을 곱해서 자주 등장하지 않는 단어에 더 큰 가중치를 줌."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca351d8",
   "metadata": {},
   "source": [
    "## Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49450c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING FOR CODE SCRIPT\n",
    "def preprocess_script(script):\n",
    "    new_script = deque()\n",
    "    with open(script,'r',encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if line.lstrip().startswith('#'): # 주석으로 시작되는 행 skip\n",
    "                continue\n",
    "            line = line.rstrip()\n",
    "            if '#' in line:\n",
    "                line = line[:line.index('#')] # 주석 전까지 코드만 저장\n",
    "            line = line.replace('\\n','') # 개행 문자를 모두 삭제함\n",
    "            line = line.replace('    ','\\t') # 공백 4칸을 tab으로 변환\n",
    "            \n",
    "            if line == '': # 전처리 후 빈 라인은 skip\n",
    "                continue\n",
    "            \n",
    "            new_script.append(line)\n",
    "            \n",
    "        new_script = '\\n'.join(new_script) # 개행 문자로 합침\n",
    "        new_script = re.sub('(\"\"\"[\\w\\W]*?\"\"\")', '<str>', new_script)\n",
    "        new_script = re.sub(\"('''[\\w\\W]*?''')\", '<str>', new_script)\n",
    "        new_script = re.sub('/^(file|gopher|news|nntp|telnet|http?|https?|ftps?|sftp):\\/\\/([a-z0-9-]+\\.)+[a-z0-9]{2,4}.*$/', '<url>', new_script)\n",
    "    \n",
    "    return new_script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02622e31-eddd-41c7-8e28-8d73d24002b9",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd4e0a3-516f-49dd-98ad-f42caf0c9cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_folder = \"./data/code/\"\n",
    "problem_folders = os.listdir(code_folder) # directory에 있는 폴더 list를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a99c605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [00:19<00:00, 15.77it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocess_scripts = []\n",
    "problem_nums = []\n",
    "\n",
    "# 300개 Sample code에 대한 전처리\n",
    "for problem_folder in tqdm(problem_folders):\n",
    "    scripts = os.listdir(os.path.join(code_folder, problem_folder)) # code/problem000/.py 파일\n",
    "    problem_num = problem_folder # 문제 번호 폴더명\n",
    "    for script in scripts:\n",
    "        script_file = os.path.join(code_folder,problem_folder,script)\n",
    "        preprocessed_script = preprocess_script(script_file)\n",
    "\n",
    "        preprocess_scripts.append(preprocessed_script)\n",
    "    # 번호 목록을 만들어서 전처리한 dataframe에 함께 넣어줌\n",
    "    problem_nums.extend([problem_num]*len(scripts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "646007ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= {'code':preprocess_scripts, 'problem_num':problem_nums})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0ecbd5-e21f-4131-869a-72177e02f660",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c0544-2c35-4562-a2c3-9cc479b5a61b",
   "metadata": {},
   "source": [
    "### Tokenizer 수행, microsoft에서 개발한 사전 학습 모델인 graphcodebert 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2366864c-6f80-470f-932d-f44a61501e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoTokenizer로 graphcodebert 사용하도록 설정\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/graphcodebert-base\")\n",
    "tokenizer.truncation_side = 'left'\n",
    "MAX_LEN = 512\n",
    "\n",
    "tokens = []\n",
    "for code in df['code']:\n",
    "    tokens.append(tokenizer.tokenize(code, max_length=MAX_LEN, truncation=True))\n",
    "\n",
    "df['tokens'] = tokens # Sample code를 Tokenization해서 tokens 컬럼에 추가\n",
    "df['len'] = df['tokens'].apply(len) # tokens의 길이를 len 컬럼에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f05e9a-437c-48c2-9403-5b605efdf4a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train과 validation data set 분리\n",
    "train_df, valid_df, train_label, valid_label = train_test_split(\n",
    "        df,\n",
    "        df['problem_num'],\n",
    "        random_state=42,\n",
    "        test_size=0.1,\n",
    "        stratify=df['problem_num']\n",
    "    )\n",
    "\n",
    "train_df = train_df.reset_index(drop=True) # Reindexing\n",
    "valid_df = valid_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af78563-b2e2-42ec-b06b-14de2cf1f8f6",
   "metadata": {},
   "source": [
    "**stratify (classification을 다룰 때 매우 중요한 옵션)**\n",
    "- default=None\n",
    "- stratify 값을 target으로 지정해주면 각각의 class 비율을 train / validation에 유지해 줌\n",
    "    - 한 쪽에 쏠려서 분배되는 것을 방지\n",
    "- 만약 이 옵션을 지정해 주지 않고 분류 문제를 다룬다면, 성능의 차이가 많이 날 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f166eb-3550-4b59-b052-8c82d015a2fd",
   "metadata": {},
   "source": [
    "----------------\n",
    "#### Create Level 1 dataset\n",
    "- Random하게 뽑은 Positive pairs와 Negative pairs로 구성\n",
    "**Train data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69927a0a-225d-467c-977c-59a798f9da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = train_df['code'].to_list() # code 컬럼을 list로 변환 - codes는 code가 쭉 나열된 형태임\n",
    "problems = train_df['problem_num'].unique().tolist() # 문제 번호를 중복을 제외하고 list로 변환\n",
    "problems.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fefea800-a433-4fe4-a71f-5c9197a144e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_positive_pairs = []\n",
    "total_negative_pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff7c78d1-f98e-4b87-ad9c-5af4a5e6c4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [00:28<00:00, 10.55it/s]\n"
     ]
    }
   ],
   "source": [
    "for problem in tqdm(problems):\n",
    "    # 각각의 문제에 대한 code를 골라 정답 코드로 저장, 아닌 문제는 other_codes로 저장\n",
    "    # 이때 train_df에는 problem_num이 정렬된 상태가 아니기 때문에 index가 다를 수 있음\n",
    "    solution_codes = train_df[train_df['problem_num'] == problem]['code'].to_list()\n",
    "    other_codes = train_df[train_df['problem_num'] != problem]['code'].to_list()\n",
    "    \n",
    "    # positive_pairs 500개 (총 300 * 1000 = 300,000개) 추출\n",
    "    # negative_pairs 500개 (총 300 * 1000 = 300,000개) 추출\n",
    "    positive_pairs = list(combinations(solution_codes,2))\n",
    "    random.shuffle(positive_pairs)\n",
    "    positive_pairs = positive_pairs[:1000]\n",
    "    random.shuffle(other_codes)\n",
    "    other_codes = other_codes[:1000]\n",
    "    \n",
    "    negative_pairs = []\n",
    "    for pos_codes, others in zip(positive_pairs, other_codes):\n",
    "        negative_pairs.append((pos_codes[0], others))\n",
    "    \n",
    "    total_positive_pairs.extend(positive_pairs)\n",
    "    total_negative_pairs.extend(negative_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "762c61d4-efe7-44d2-9232-138c79ee71f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_positive_pairs와 negative_pairs의 정답 코드를 묶어 code1로 지정\n",
    "# total_positive_pairs와 negative_pairs의 비교 대상 코드를 묶어 code2로 지정\n",
    "# 해당 코드에 맞는 label 설정\n",
    "code1 = [code[0] for code in total_positive_pairs] + [code[0] for code in total_negative_pairs]\n",
    "code2 = [code[1] for code in total_positive_pairs] + [code[1] for code in total_negative_pairs]\n",
    "label = [1]*len(total_positive_pairs) + [0]*len(total_negative_pairs)\n",
    "\n",
    "# DataFrame으로 선언\n",
    "train_data = pd.DataFrame(data={'code1':code1, 'code2':code2, 'similar':label})\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True) # frac: 추출할 표본 비율\n",
    "train_data.to_csv('data/train_data_lv1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208c1b9b-38e5-47d7-b6c4-12c8205f2167",
   "metadata": {},
   "source": [
    "**Validation data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "024636b3-563c-4719-8d55-534ba3fc8a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = valid_df['code'].to_list() # code 컬럼을 list로 변환 - codes는 code가 쭉 나열된 형태임\n",
    "problems = valid_df['problem_num'].unique().tolist() # 문제 번호를 중복을 제외하고 list로 변환\n",
    "problems.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c17c3e87-0389-4316-84a5-82faae168e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_positive_pairs = []\n",
    "total_negative_pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b622cf2-0b5f-4b00-8253-d900e48ed121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 300/300 [00:03<00:00, 87.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for problem in tqdm(problems):\n",
    "    # 각각의 문제에 대한 code를 골라 정답 코드로 저장, 아닌 문제는 other_codes로 저장\n",
    "    # 이때 train_df에는 problem_num이 정렬된 상태가 아니기 때문에 index가 다를 수 있음\n",
    "    solution_codes = valid_df[valid_df['problem_num'] == problem]['code'].to_list()\n",
    "    other_codes = valid_df[valid_df['problem_num'] != problem]['code'].to_list()\n",
    "    \n",
    "    # positive_pairs 500개 (총 300 * 100 = 30,000개) 추출\n",
    "    # negative_pairs 500개 (총 300 * 100 = 30,000개) 추출\n",
    "    positive_pairs = list(combinations(solution_codes,2))\n",
    "    random.shuffle(positive_pairs)\n",
    "    positive_pairs = positive_pairs[:100]\n",
    "    random.shuffle(other_codes)\n",
    "    other_codes = other_codes[:100]\n",
    "    \n",
    "    negative_pairs = []\n",
    "    for pos_codes, others in zip(positive_pairs, other_codes):\n",
    "        negative_pairs.append((pos_codes[0], others))\n",
    "    \n",
    "    total_positive_pairs.extend(positive_pairs)\n",
    "    total_negative_pairs.extend(negative_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37a580c6-16ae-42df-b57f-5bbd9ecc989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_positive_pairs와 negative_pairs의 정답 코드를 묶어 code1로 지정\n",
    "# total_positive_pairs와 negative_pairs의 비교 대상 코드를 묶어 code2로 지정\n",
    "# 해당 코드에 맞는 label 설정\n",
    "code1 = [code[0] for code in total_positive_pairs] + [code[0] for code in total_negative_pairs]\n",
    "code2 = [code[1] for code in total_positive_pairs] + [code[1] for code in total_negative_pairs]\n",
    "label = [1]*len(total_positive_pairs) + [0]*len(total_negative_pairs)\n",
    "\n",
    "# DataFrame으로 선언\n",
    "valid_data = pd.DataFrame(data={'code1':code1, 'code2':code2, 'similar':label})\n",
    "valid_data = valid_data.sample(frac=1).reset_index(drop=True) # frac: 추출할 표본 비율\n",
    "valid_data.to_csv('data/valid_data_lv1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0bf80c-5118-4f79-914e-8d4b7bc1143f",
   "metadata": {
    "tags": []
   },
   "source": [
    "-------------\n",
    "#### Create Middle Level dataset\n",
    "- 유사도가 중간인 코드들의 Positive pairs와 Negative pairs로 이루어짐  \n",
    "    (사용해본 결과 그닥 성능이 좋지않아 사용하지 않음)\n",
    "**Training data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ceef72d8-006e-4348-9d8e-5d5b20db51bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 300/300 [1:51:03<00:00, 22.21s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "codes = train_df['code'].to_list() # code 컬럼을 list로 변환 - codes는 code가 쭉 나열된 형태임\n",
    "problems = train_df['problem_num'].unique().tolist() # 문제 번호를 중복을 제외하고 list로 변환\n",
    "problems.sort()\n",
    "\n",
    "# # code를 토큰화하여 저장, train_df에 저장된 모든 코드들에 대한 token들을 리스트 하나에 저장함\n",
    "# tokenized_corpus = train_df['tokens'].to_list()\n",
    "# # 토큰화된 code에 대해 상관관계를 계산, 현재 무작위로 설정된 code에 대해서 수행하기 때문에\n",
    "# # 상관관계를 계산하는 코드는 같은 문제를 푸는 코드가 아닐 수 있음.\n",
    "# bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "total_positive_pairs = []\n",
    "total_negative_pairs = []\n",
    "\n",
    "for problem in tqdm(problems):\n",
    "    # 각각의 문제에 대한 code를 골라 정답 코드로 저장, 아닌 문제는 other_solutions로 저장\n",
    "    solutions = train_df[train_df['problem_num'] == problem]\n",
    "    other_solutions = train_df[train_df['problem_num'] != problem]\n",
    "    \n",
    "    positive_pairs = []\n",
    "    negative_pairs = []\n",
    "    \n",
    "    # 같은 문제를 푸는 코드에 대한 토큰을 저장\n",
    "    pp_tokens = solutions['tokens'].to_list()\n",
    "    np_tokens = other_solutions['tokens'].to_list()\n",
    "    ppbm25 = BM25Okapi(pp_tokens)\n",
    "    npbm25 = BM25Okapi(np_tokens)\n",
    "    \n",
    "    # 각각의 코드에 대해 유사도 비교하여 pairs에 추가\n",
    "    for solution, token in list(zip(solutions['code'], solutions['tokens']))[:10]: # solution_codes: 약 135\n",
    "        pp_scores = ppbm25.get_scores(token)\n",
    "        np_scores = npbm25.get_scores(token)\n",
    "        pos_idx = round(len(pp_scores)/2) # pos_idx: 135 / 2 = 약 68\n",
    "        neg_idx = round(len(np_scores)/2) # neg_idx: 40450 / 2 = 20,225\n",
    "        positive_code_ranking = pp_scores.argsort()[::1][pos_idx:]\n",
    "        negative_code_ranking = np_scores.argsort()[::-1][neg_idx:]\n",
    "        \n",
    "        # positive, negative pairs의 길이는 코드당 15개 (총 (300 * 10 * 15) * 2 = 90,000개)\n",
    "        for i in range(15):\n",
    "            score_idx = positive_code_ranking[i]\n",
    "            positive_pairs.append((solution, train_df['code'].iloc[score_idx]))\n",
    "        \n",
    "        for i in range(15):\n",
    "            score_idx = negative_code_ranking[i]\n",
    "            negative_pairs.append((solution, train_df['code'].iloc[score_idx]))\n",
    "\n",
    "            \n",
    "    total_positive_pairs.extend(positive_pairs)\n",
    "    total_negative_pairs.extend(negative_pairs)\n",
    "    \n",
    "# total_positive_pairs와 negative_pairs의 정답 코드를 묶어 code1로 지정\n",
    "# total_positive_pairs와 negative_pairs의 비교 대상 코드를 묶어 code2로 지정\n",
    "# 해당 코드에 맞는 label 설정\n",
    "code1 = [code[0] for code in total_positive_pairs] + [code[0] for code in total_negative_pairs]\n",
    "code2 = [code[1] for code in total_positive_pairs] + [code[1] for code in total_negative_pairs]\n",
    "label = [1]*len(total_positive_pairs) + [0]*len(total_negative_pairs)\n",
    "\n",
    "# DataFrame으로 선언\n",
    "middle_data = pd.DataFrame(data={'code1':code1, 'code2':code2, 'similar':label})\n",
    "middle_data = middle_data.sample(frac=1).reset_index(drop=True) # frac: 추출할 표본 비율\n",
    "middle_data.to_csv('data/train_data_Middle.csv',index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4417fd18-0c54-46a8-b0fc-c6506031e7cb",
   "metadata": {},
   "source": [
    "-------------\n",
    "#### Create High Level dataset\n",
    "- 유사도가 낮은 Positive pairs와 유사도가 높은 Negative pairs로 이루어짐  \n",
    "    (역시 성능이 좋지않아 사용하지 않음)\n",
    "**Training data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "03ea3ae8-b7de-455a-ab42-b71135533449",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "codes = train_df['code'].to_list() # code 컬럼을 list로 변환 - codes는 code가 쭉 나열된 형태임\n",
    "problems = train_df['problem_num'].unique().tolist() # 문제 번호를 중복을 제외하고 list로 변환\n",
    "problems.sort()\n",
    "\n",
    "total_positive_pairs = []\n",
    "total_negative_pairs = []\n",
    "\n",
    "for problem in tqdm(problems):\n",
    "    # 각각의 문제에 대한 code를 골라 정답 코드로 저장, 아닌 문제는 other_solutions로 저장\n",
    "    solutions = train_df[train_df['problem_num'] == problem]\n",
    "    other_solutions = train_df[train_df['problem_num'] != problem]\n",
    "    \n",
    "    positive_pairs = []\n",
    "    negative_pairs = []\n",
    "    \n",
    "    # 같은 문제를 푸는 코드에 대한 토큰을 저장\n",
    "    pp_tokens = solutions['tokens'].to_list()\n",
    "    np_tokens = other_solutions['tokens'].to_list()\n",
    "    ppbm25 = BM25Okapi(pp_tokens)\n",
    "    npbm25 = BM25Okapi(np_tokens)\n",
    "    \n",
    "    # 각각의 코드에 대해 유사도 비교하여 pairs에 추가\n",
    "    for solution, token in list(zip(solutions['code'], solutions['tokens']))[:10]: # solution_codes: 약 135\n",
    "        pp_scores = ppbm25.get_scores(token)\n",
    "        np_scores = npbm25.get_scores(token)\n",
    "        positive_code_ranking = pp_scores.argsort()[::1]\n",
    "        negative_code_ranking = np_scores.argsort()[::-1]\n",
    "        \n",
    "        # positive, negative pairs의 길이는 코드당 15개 (총 (300 * 10 * 15) * 2 = 90,000개)\n",
    "        for i in range(15):\n",
    "            score_idx = positive_code_ranking[i]\n",
    "            positive_pairs.append((solution, train_df['code'].iloc[score_idx]))\n",
    "        \n",
    "        for i in range(15):\n",
    "            score_idx = negative_code_ranking[i]\n",
    "            negative_pairs.append((solution, train_df['code'].iloc[score_idx]))\n",
    "\n",
    "            \n",
    "    total_positive_pairs.extend(positive_pairs)\n",
    "    total_negative_pairs.extend(negative_pairs)\n",
    "    \n",
    "# total_positive_pairs와 negative_pairs의 정답 코드를 묶어 code1로 지정\n",
    "# total_positive_pairs와 negative_pairs의 비교 대상 코드를 묶어 code2로 지정\n",
    "# 해당 코드에 맞는 label 설정\n",
    "code1 = [code[0] for code in total_positive_pairs] + [code[0] for code in total_negative_pairs]\n",
    "code2 = [code[1] for code in total_positive_pairs] + [code[1] for code in total_negative_pairs]\n",
    "label = [1]*len(total_positive_pairs) + [0]*len(total_negative_pairs)\n",
    "\n",
    "# DataFrame으로 선언\n",
    "high_data = pd.DataFrame(data={'code1':code1, 'code2':code2, 'similar':label})\n",
    "high_data = high_data.sample(frac=1).reset_index(drop=True) # frac: 추출할 표본 비율\n",
    "high_data.to_csv('data/train_data_High.csv',index=False)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
